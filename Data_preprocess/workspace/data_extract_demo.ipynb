{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 데이터 추출을 위한 데모 파일\n",
    "- 데이터 프레임의 특정 열에서 단어를 추출하는 작업\n",
    "- 자연어 전처리 프로세스를 통해 고유한 단어를 추출"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "c:\\Users\\PC\\Desktop\\git_repo\\ML-DL-Training\\Data_preprocess\\workspace\\file\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from openpyxl import load_workbook\n",
    "import os\n",
    "import re\n",
    "from nltk.corpus import stopwords\n",
    "from collections import Counter\n",
    "\n",
    "\n",
    "dir_path = os.getcwd()\n",
    "dir_path = os.path.join(dir_path, \"file\")\n",
    "print(dir_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\PC\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('stopwords')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1차 정리 단어 추출 작업"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 특수 문자 제거 및 숫자 제거\n",
    "- 공백 기준 단어 분리\n",
    "- 불용어 제거, 길이가 2이하인 단어 제거"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 파일 경로와 읽을 열 이름\n",
    "file_name = \"eclass_property.xlsx\"\n",
    "file_path = os.path.join(dir_path,file_name)  # 여기에 엑셀 파일 경로를 넣으세요.\n",
    "column_name = 'Preferred name'  # 여기에 열 이름을 넣으세요.\n",
    "\n",
    "# 엑셀 파일 읽기\n",
    "df = pd.read_excel(file_path)\n",
    "\n",
    "# 특수문자 및 숫자 제거 함수\n",
    "def remove_special_characters(text):\n",
    "    text = re.sub(r'[^A-Za-z\\s]', ' ', text)\n",
    "    text = re.sub(r'\\s+', ' ', text).strip()\n",
    "\n",
    "    return text\n",
    "\n",
    "# 공백 기준 단어 분리, 불용어 제거, 길이가 2이하인 함수\n",
    "def process_text(text):\n",
    "    words = text.split()\n",
    "    filtered_words = [word[0].upper() + word[1:] for word in words if word.lower() not in stopwords.words('english') and len(word) > 2]\n",
    "    \n",
    "    return filtered_words\n",
    "\n",
    "# 해당 열의 단어 추출 및 처리\n",
    "all_words = []\n",
    "for text in df[column_name].dropna():\n",
    "    cleaned_text = remove_special_characters(text)\n",
    "    words = process_text(cleaned_text)\n",
    "    all_words.extend(words)\n",
    "\n",
    "\n",
    "# 단어 빈도수 계산\n",
    "word_freq = Counter(all_words)\n",
    "\n",
    "# 결과를 데이터프레임으로 변환\n",
    "result_df = pd.DataFrame(word_freq.items(), columns=['Word', 'Frequency'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<bound method NDFrame.describe of          Word  Frequency\n",
       "0       FRONT        152\n",
       "1        TYPE        149\n",
       "2      CORPUS        303\n",
       "3       Total        137\n",
       "4       Front         68\n",
       "...       ...        ...\n",
       "7445   Foamed          1\n",
       "7446     ZERO          3\n",
       "7447   ADJUST          1\n",
       "7448  Zeroset          1\n",
       "7449     Zinc          2\n",
       "\n",
       "[7450 rows x 2 columns]>"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result_df.describe"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 대문자 중복 단어 제거\n",
    "- 축약어, 단어 분리 처리"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [],
   "source": [
    "column_data = result_df['Word'].dropna()\n",
    "\n",
    "upper_data = pd.DataFrame()\n",
    "lower_data = pd.DataFrame()\n",
    "\n",
    "# 대문자 2개 이상(upper_data), 1개 이하(lower_data) 데이터 분리\n",
    "upper_data['Word'] = column_data[column_data.str.contains(r'[A-Z].*[A-Z]')]             # 870개\n",
    "lower_data['Word'] = column_data[~column_data.str.contains(r'[A-Z].*[A-Z]', na=False)]  # 6580개\n",
    "\n",
    "# 소문자 통일 처리\n",
    "upper_data['UP_Lower'] = upper_data['Word'].str.lower().to_frame()\n",
    "lower_data['LO_Lower'] = lower_data['Word'].str.lower().to_frame()\n",
    "\n",
    "# lower_data를 기준으로 inner merge\n",
    "merged_df = pd.merge(upper_data, lower_data, left_on='UP_Lower', right_on='LO_Lower', how='inner')\n",
    "\n",
    "# upper_data 중 중복이 아닌 데이터 분리\n",
    "upper_only_data = upper_data.loc[~upper_data['UP_Lower'].isin(merged_df['UP_Lower']), ['Word']] #614개\n",
    "\n",
    "# lower_data 중 중복이 아닌 데이터 분리\n",
    "lower_only_data = lower_data.loc[~lower_data['LO_Lower'].isin(merged_df['LO_Lower']), ['Word']] #6324개\n",
    "\n",
    "# overlap data 정리\n",
    "overlap_data = merged_df[['Word_y']].rename(columns={'Word_y': 'Word'})                         #256개\n",
    "\n",
    "# word data 정리\n",
    "word_data = pd.concat([lower_only_data, overlap_data], ignore_index=True)                       #6580개\n",
    "word_data['Word'] = word_data['Word'].str.lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Word</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>total</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>phase</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>current</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>possible</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>pointer</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6575</th>\n",
       "      <td>vortex</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6576</th>\n",
       "      <td>width</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6577</th>\n",
       "      <td>lock</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6578</th>\n",
       "      <td>zero</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6579</th>\n",
       "      <td>adjust</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>6580 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          Word\n",
       "0        total\n",
       "1        phase\n",
       "2      current\n",
       "3     possible\n",
       "4      pointer\n",
       "...        ...\n",
       "6575    vortex\n",
       "6576     width\n",
       "6577      lock\n",
       "6578      zero\n",
       "6579    adjust\n",
       "\n",
       "[6580 rows x 1 columns]"
      ]
     },
     "execution_count": 177,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 표제어 변환"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\PC\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package omw-1.4 to\n",
      "[nltk_data]     C:\\Users\\PC\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package omw-1.4 is already up-to-date!\n",
      "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
      "[nltk_data]     C:\\Users\\PC\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
      "[nltk_data]       date!\n",
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\PC\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package words to\n",
      "[nltk_data]     C:\\Users\\PC\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package words is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 218,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from textblob import TextBlob, Word\n",
    "from nltk import pos_tag\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.stem import PorterStemmer\n",
    "from nltk.corpus import wordnet, words\n",
    "\n",
    "import inflect\n",
    "\n",
    "nltk.download('wordnet')\n",
    "nltk.download('omw-1.4')\n",
    "nltk.download('averaged_perceptron_tagger')\n",
    "nltk.download('punkt')\n",
    "nltk.download('words')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 235,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Steemmer를 사용하여 단어의 원형 추출\n",
    "def stemmer(word):\n",
    "    ps = PorterStemmer()\n",
    "    return ps.stem(word)\n",
    "\n",
    "p = inflect.engine()\n",
    "\n",
    "# 단수형 변환 함수 정의\n",
    "def to_singular(word):\n",
    "    singular_word = p.singular_noun(word)\n",
    "    return singular_word if singular_word else word\n",
    "\n",
    "EN_words = set(words.words())\n",
    "\n",
    "# 영어 단어 인지 확인\n",
    "def is_EN_word(word):\n",
    "    if word in EN_words:\n",
    "        return word\n",
    "        \n",
    "\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "\n",
    "# 품사 태그를 WordNet의 태그로 변환\n",
    "def get_wordnet_pos(treebank_tag):\n",
    "    if treebank_tag.startswith('J'):\n",
    "        return wordnet.ADJ\n",
    "    elif treebank_tag.startswith('V'):\n",
    "        return wordnet.VERB\n",
    "    elif treebank_tag.startswith('N'):\n",
    "        return wordnet.NOUN\n",
    "    elif treebank_tag.startswith('R'):\n",
    "        return wordnet.ADV\n",
    "    else:\n",
    "        return wordnet.NOUN\n",
    "\n",
    "# 원형을 추출\n",
    "def get_lemma(word):\n",
    "    pos = pos_tag([word])[0][1]  # 단어의 품사 태깅\n",
    "    wordnet_pos = get_wordnet_pos(pos)  # WordNet의 품사 태그로 변환\n",
    "    lemma = lemmatizer.lemmatize(word, wordnet_pos)  # 원형 추출\n",
    "    return lemma"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 237,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 데이터프레임에 단어의 원형 추출\n",
    "word_result = pd.DataFrame()\n",
    "\n",
    "# 추출 단어의 단수형 추출, nltk 내의 word에서 존재여부 파악, 중복 처리\n",
    "word_result['Word'] = word_data['Word'].apply(lambda x: is_EN_word(to_singular(x))).dropna().drop_duplicates()\n",
    "\n",
    "# 추출 단어의 어간 추출(Stemming)\n",
    "word_result['Stemm_Word'] = word_result['Word'].apply(stemmer)\n",
    "\n",
    "# 어간 추출 단어와 기존 단어의 비교\n",
    "word_result['Data_Equal'] = word_result.eval('Word == Stemm_Word')\n",
    "\n",
    "# 어간 추출 단어와 다른 단어중 nltk 내의 word에서 존재여부 파악 \n",
    "Stemm_Word = word_result[word_result['Data_Equal'] == False][['Stemm_Word']]\n",
    "word_result['Stem_con'] = Stemm_Word['Stemm_Word'].apply(is_EN_word)\n",
    "\n",
    "# 최종 결과 col생성\n",
    "word_result['Result_word'] = word_result.apply(\n",
    "    lambda row: row['Word'] if row['Data_Equal'] else (row['Stemm_Word'] if row['Stem_con'] else row['Word']),\n",
    "    axis=1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 238,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Word</th>\n",
       "      <th>Stemm_Word</th>\n",
       "      <th>Data_Equal</th>\n",
       "      <th>Stem_con</th>\n",
       "      <th>Result_word</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>total</td>\n",
       "      <td>total</td>\n",
       "      <td>True</td>\n",
       "      <td>NaN</td>\n",
       "      <td>total</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>phase</td>\n",
       "      <td>phase</td>\n",
       "      <td>True</td>\n",
       "      <td>NaN</td>\n",
       "      <td>phase</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>current</td>\n",
       "      <td>current</td>\n",
       "      <td>True</td>\n",
       "      <td>NaN</td>\n",
       "      <td>current</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>possible</td>\n",
       "      <td>possibl</td>\n",
       "      <td>False</td>\n",
       "      <td>None</td>\n",
       "      <td>possible</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>pointer</td>\n",
       "      <td>pointer</td>\n",
       "      <td>True</td>\n",
       "      <td>NaN</td>\n",
       "      <td>pointer</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6574</th>\n",
       "      <td>index</td>\n",
       "      <td>index</td>\n",
       "      <td>True</td>\n",
       "      <td>NaN</td>\n",
       "      <td>index</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6575</th>\n",
       "      <td>vortex</td>\n",
       "      <td>vortex</td>\n",
       "      <td>True</td>\n",
       "      <td>NaN</td>\n",
       "      <td>vortex</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6576</th>\n",
       "      <td>width</td>\n",
       "      <td>width</td>\n",
       "      <td>True</td>\n",
       "      <td>NaN</td>\n",
       "      <td>width</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6578</th>\n",
       "      <td>zero</td>\n",
       "      <td>zero</td>\n",
       "      <td>True</td>\n",
       "      <td>NaN</td>\n",
       "      <td>zero</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6579</th>\n",
       "      <td>adjust</td>\n",
       "      <td>adjust</td>\n",
       "      <td>True</td>\n",
       "      <td>NaN</td>\n",
       "      <td>adjust</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4431 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          Word Stemm_Word  Data_Equal Stem_con Result_word\n",
       "0        total      total        True      NaN       total\n",
       "1        phase      phase        True      NaN       phase\n",
       "2      current    current        True      NaN     current\n",
       "3     possible    possibl       False     None    possible\n",
       "4      pointer    pointer        True      NaN     pointer\n",
       "...        ...        ...         ...      ...         ...\n",
       "6574     index      index        True      NaN       index\n",
       "6575    vortex     vortex        True      NaN      vortex\n",
       "6576     width      width        True      NaN       width\n",
       "6578      zero       zero        True      NaN        zero\n",
       "6579    adjust     adjust        True      NaN      adjust\n",
       "\n",
       "[4431 rows x 5 columns]"
      ]
     },
     "execution_count": 238,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 245,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<bound method NDFrame.describe of 0          total\n",
       "1          phase\n",
       "2        current\n",
       "3       possible\n",
       "4        pointer\n",
       "          ...   \n",
       "6565         duo\n",
       "6574       index\n",
       "6575      vortex\n",
       "6576       width\n",
       "6578        zero\n",
       "Name: Result_word, Length: 3893, dtype: object>"
      ]
     },
     "execution_count": 245,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_result[\"Result_word\"].drop_duplicates().describe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 240,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 결과 엑셀 시트에 분할 저장\n",
    "\n",
    "result_file_path = os.path.join(dir_path,'processed_words_r.xlsx')\n",
    "with pd.ExcelWriter(result_file_path) as writer:\n",
    "    word_result.to_excel(writer, sheet_name='Sheet1', index=False)\n",
    "    upper_only_data.to_excel(writer, sheet_name='Sheet2', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 231,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 결과 엑셀 파일로 저장\n",
    "result_file_path = os.path.join(dir_path,'processed_words_1.xlsx')\n",
    "result_df.to_excel(result_file_path, index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "interX_work",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
