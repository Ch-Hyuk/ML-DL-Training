{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#image load\n",
    "\n",
    "path_dir = './LFW-FER/eval/negative/'\n",
    "file_list = os.listdir(path_dir)\n",
    "\n",
    "# file_list[0]\n",
    "img = cv2.imread(path_dir + file_list[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- ### OpenCV HarrCascadeClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "if img is None:\n",
    "    print('Image load failed!')\n",
    "    os.sys.exit()\n",
    "\n",
    "# 객체 생성\n",
    "classifier = cv2.CascadeClassifier(cv2.data.haarcascades +'haarcascade_frontalface_default.xml')\n",
    "eye_cascade = cv2.CascadeClassifier(cv2.data.haarcascades + 'haarcascade_eye.xml')\n",
    "\n",
    "\n",
    "# 개체가 재대로 생성됬는지 확인\n",
    "if classifier.empty():\n",
    "    print('XML load failed!')\n",
    "    os.sys.exit()\n",
    "\n",
    "# 입력영상에서 얼굴을 검출\n",
    "faces = classifier.detectMultiScale(img) # 스케일팩터를 1.2로 지정해도 잘 작동함 더 빨라짐\n",
    "\n",
    "# 각각의 행마다 (x,y,w,h) 받아와서 사각형을 그리는 코드\n",
    "for (x, y, w, h) in faces:\n",
    "    cv2.rectangle(img, (x, y, w, h), (255, 0, 255), 2)\n",
    "\n",
    "\n",
    "cv2.imshow('face_detection', img)\n",
    "cv2.waitKey()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### DlibHOGFaceDetector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import dlib\n",
    "import sys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing file: --ip=127.0.0.1\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "Unable to open file: --ip=127.0.0.1",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-11-179cc0dfa527>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mf\u001b[0m \u001b[1;32min\u001b[0m \u001b[0msys\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0margv\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m     \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Processing file: {}\"\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mf\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 6\u001b[1;33m     \u001b[0mimg\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdlib\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mload_rgb_image\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mf\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      7\u001b[0m     \u001b[1;31m# The 1 in the second argument indicates that we should upsample the image\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      8\u001b[0m     \u001b[1;31m# 1 time.  This will make everything bigger and allow us to detect more\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mRuntimeError\u001b[0m: Unable to open file: --ip=127.0.0.1"
     ]
    }
   ],
   "source": [
    "detector = dlib.get_frontal_face_detector()\n",
    "win = dlib.image_window()\n",
    "\n",
    "for f in sys.argv[1:]:\n",
    "    print(\"Processing file: {}\".format(f))\n",
    "    img = dlib.load_rgb_image(f)\n",
    "    # The 1 in the second argument indicates that we should upsample the image\n",
    "    # 1 time.  This will make everything bigger and allow us to detect more\n",
    "    # faces.\n",
    "    dets = detector(img, 1)\n",
    "    print(\"Number of faces detected: {}\".format(len(dets)))\n",
    "    for i, d in enumerate(dets):\n",
    "        print(\"Detection {}: Left: {} Top: {} Right: {} Bottom: {}\".format(\n",
    "            i, d.left(), d.top(), d.right(), d.bottom()))\n",
    "\n",
    "    win.clear_overlay()\n",
    "    win.set_image(img)\n",
    "    win.add_overlay(dets)\n",
    "    dlib.hit_enter_to_continue()\n",
    "\n",
    "\n",
    "# Finally, if you really want to you can ask the detector to tell you the score\n",
    "# for each detection.  The score is bigger for more confident detections.\n",
    "# The third argument to run is an optional adjustment to the detection threshold,\n",
    "# where a negative value will return more detections and a positive value fewer.\n",
    "# Also, the idx tells you which of the face sub-detectors matched.  This can be\n",
    "# used to broadly identify faces in different orientations.\n",
    "if (len(sys.argv[1:]) > 0):\n",
    "    img = dlib.load_rgb_image(sys.argv[1])\n",
    "    dets, scores, idx = detector.run(img, 1, -1)\n",
    "    for i, d in enumerate(dets):\n",
    "        print(\"Detection {}, score: {}, face_type:{}\".format(\n",
    "            d, scores[i], idx[i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "detector = dlib.get_frontal_face_detector()\n",
    "faces = detector(img)\n",
    "\n",
    "for face in faces:\n",
    "    left = face.left()\n",
    "    right = face.right()\n",
    "    top = face.top()\n",
    "    bottom = face.bottom()\n",
    "    print(left, right, top, bottom)\n",
    "    # 위치 정보를 활용해 사각형 그리기\n",
    "    img = cv2.rectangle(\n",
    "        img, (left, top), (right, bottom), (0, 0, 255), 3\n",
    "    )\n",
    "    cv2.imwrite(\"./face_data/face-rect_test.jpg\", img)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### DlibCNNFaceDetector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!/usr/bin/python\n",
    "# The contents of this file are in the public domain. See LICENSE_FOR_EXAMPLE_PROGRAMS.txt\n",
    "#\n",
    "#   This example shows how to run a CNN based face detector using dlib.  The\n",
    "#   example loads a pretrained model and uses it to find faces in images.  The\n",
    "#   CNN model is much more accurate than the HOG based model shown in the\n",
    "#   face_detector.py example, but takes much more computational power to\n",
    "#   run, and is meant to be executed on a GPU to attain reasonable speed.\n",
    "#\n",
    "#   You can download the pre-trained model from:\n",
    "#       http://dlib.net/files/mmod_human_face_detector.dat.bz2\n",
    "#\n",
    "#   The examples/faces folder contains some jpg images of people.  You can run\n",
    "#   this program on them and see the detections by executing the\n",
    "#   following command:\n",
    "#       ./cnn_face_detector.py mmod_human_face_detector.dat ../examples/faces/*.jpg\n",
    "#\n",
    "#\n",
    "# COMPILING/INSTALLING THE DLIB PYTHON INTERFACE\n",
    "#   You can install dlib using the command:\n",
    "#       pip install dlib\n",
    "#\n",
    "#   Alternatively, if you want to compile dlib yourself then go into the dlib\n",
    "#   root folder and run:\n",
    "#       python setup.py install\n",
    "#\n",
    "#   Compiling dlib should work on any operating system so long as you have\n",
    "#   CMake installed.  On Ubuntu, this can be done easily by running the\n",
    "#   command:\n",
    "#       sudo apt-get install cmake\n",
    "#\n",
    "#   Also note that this example requires Numpy which can be installed\n",
    "#   via the command:\n",
    "#       pip install numpy\n",
    "\n",
    "import sys\n",
    "import dlib\n",
    "\n",
    "if len(sys.argv) < 3:\n",
    "    print(\n",
    "        \"Call this program like this:\\n\"\n",
    "        \"   ./cnn_face_detector.py mmod_human_face_detector.dat ../examples/faces/*.jpg\\n\"\n",
    "        \"You can get the mmod_human_face_detector.dat file from:\\n\"\n",
    "        \"    http://dlib.net/files/mmod_human_face_detector.dat.bz2\")\n",
    "    exit()\n",
    "\n",
    "cnn_face_detector = dlib.cnn_face_detection_model_v1(sys.argv[1])\n",
    "win = dlib.image_window()\n",
    "\n",
    "for f in sys.argv[2:]:\n",
    "    print(\"Processing file: {}\".format(f))\n",
    "    img = dlib.load_rgb_image(f)\n",
    "    # The 1 in the second argument indicates that we should upsample the image\n",
    "    # 1 time.  This will make everything bigger and allow us to detect more\n",
    "    # faces.\n",
    "    dets = cnn_face_detector(img, 1)\n",
    "    '''\n",
    "    This detector returns a mmod_rectangles object. This object contains a list of mmod_rectangle objects.\n",
    "    These objects can be accessed by simply iterating over the mmod_rectangles object\n",
    "    The mmod_rectangle object has two member variables, a dlib.rectangle object, and a confidence score.\n",
    "    \n",
    "    It is also possible to pass a list of images to the detector.\n",
    "        - like this: dets = cnn_face_detector([image list], upsample_num, batch_size = 128)\n",
    "\n",
    "    In this case it will return a mmod_rectangless object.\n",
    "    This object behaves just like a list of lists and can be iterated over.\n",
    "    '''\n",
    "    print(\"Number of faces detected: {}\".format(len(dets)))\n",
    "    for i, d in enumerate(dets):\n",
    "        print(\"Detection {}: Left: {} Top: {} Right: {} Bottom: {} Confidence: {}\".format(\n",
    "            i, d.rect.left(), d.rect.top(), d.rect.right(), d.rect.bottom(), d.confidence))\n",
    "\n",
    "    rects = dlib.rectangles()\n",
    "    rects.extend([d.rect for d in dets])\n",
    "\n",
    "    win.clear_overlay()\n",
    "    win.set_image(img)\n",
    "    win.add_overlay(rects)\n",
    "    dlib.hit_enter_to_continue()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MTCNN(Multi-task Cascaded Convolutional Networks)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dlib Facial Landmarks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import dlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "Unable to open shape_predictor_68_face_landmarks.dat",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-2-bd13152fdec9>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0mface_detector\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdlib\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_frontal_face_detector\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mlandmark_detector\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdlib\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape_predictor\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"shape_predictor_68_face_landmarks.dat\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m: Unable to open shape_predictor_68_face_landmarks.dat"
     ]
    }
   ],
   "source": [
    "face_detector = dlib.get_frontal_face_detector()\n",
    "landmark_detector = dlib.shape_predictor(\"shape_predictor_68_face_landmarks.dat\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "faces = face_detector(img, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "landmark_tuple = []\n",
    "for k, d in enumerate(faces):\n",
    "    landmarks = landmark_detector(img, d)\n",
    "    for n in range(0, 27):\n",
    "        x = landmarks.part(n).x\n",
    "        y = landmarks.part(n).y\n",
    "        landmark_tuple.append((x, y))\n",
    "        cv2.circle(img, (x, y), 2, (255, 255, 0), -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "OpenCV",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
