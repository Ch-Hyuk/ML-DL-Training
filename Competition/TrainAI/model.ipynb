{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2023 제1회 철도 인공지능 경진대회\n",
    "- 주어진 주행데이터 및 선로데이터를 이용하여, 탈선계수에 해당하는 이하 4개 항목을 예측하는 모델을 만듭니다.\n",
    "    - YL_M1_B1_W1: 좌측 전위 차륜 탈선계수\n",
    "    - YR_M1_B1_W1: 우측 전위 차륜 탈선계수\n",
    "    - YL_M1_B1_W2: 좌측 후위 차륜 탈선계수\n",
    "    - YR_M1_B1_W2: 우측 후위 차륜 탈선계수"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "\n",
    "from tqdm.notebook import tqdm\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_c30 = pd.read_csv('./data/data_c30.csv')\n",
    "data_c40 = pd.read_csv('./data/data_c40.csv')\n",
    "data_c50 = pd.read_csv('./data/data_c50.csv')\n",
    "data_c70 = pd.read_csv('./data/data_c70.csv')\n",
    "data_c100 = pd.read_csv('./data/data_c100.csv')\n",
    "\n",
    "lane_data_c = pd.read_csv('./data/lane_data_c.csv')\n",
    "\n",
    "data_s30 = pd.read_csv('./data/data_s30.csv')\n",
    "data_s40 = pd.read_csv('./data/data_s40.csv')\n",
    "data_s50 = pd.read_csv('./data/data_s50.csv')\n",
    "data_s70 = pd.read_csv('./data/data_s70.csv')\n",
    "data_s100 = pd.read_csv('./data/data_s100.csv')\n",
    "\n",
    "lane_data_s = pd.read_csv('./data/lane_data_s.csv')\n",
    "\n",
    "answer_sample = pd.read_csv('./data/answer_sample.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#train data\n",
    "s_datas = {\n",
    "    's30':[data_s30, lane_data_s],\n",
    "    's40':[data_s40, lane_data_s],\n",
    "    's50':[data_s50, lane_data_s],\n",
    "    's70':[data_s70, lane_data_s],\n",
    "    's100':[data_s100, lane_data_s]\n",
    "    }\n",
    "\n",
    "c_datas = {\n",
    "    'c30':[data_c30, lane_data_c],\n",
    "    'c40':[data_c40, lane_data_c],\n",
    "    'c50':[data_c50, lane_data_c],\n",
    "    'c70':[data_c70, lane_data_c],\n",
    "    'c100':[data_c100, lane_data_c]\n",
    "    }\n",
    "\n",
    "#answer를 위한 data\n",
    "test_data = {\n",
    "    's30':None,\n",
    "    's40':None,\n",
    "    's50':None,\n",
    "    's70':None,\n",
    "    's100':None,\n",
    "    'c30':None,\n",
    "    'c40':None,\n",
    "    'c50':None,\n",
    "    'c70':None,\n",
    "    'c100':None,\n",
    "    }\n",
    "\n",
    "# 하이퍼파라미터 설정\n",
    "#TEST0: LSTM        epoch 100, hidden_size 64, num_layers 2, seq_length 100\n",
    "#TEST1: GRU         epoch 100, hidden_size 64, num_layers 2, seq_length 100\n",
    "#TEST2: LSTMGRU     epoch 100, lstm_hidden_size 64, lstm_num_layers 2, gru_hidden_size 64, gru_num_layers 2, seq_length 100  \n",
    "#TEST2: LSTMGRU     epoch 100, lstm_hidden_size 32, lstm_num_layers 2, gru_hidden_size 32, gru_num_layers 2, seq_length 100  -> 0.0014\n",
    "\n",
    "hyperparameter = {\n",
    "        'test_number':0,\n",
    "        'load_number':0,\n",
    "        'flag':False,\n",
    "        's_input_size':36,\n",
    "        'c_input_size':34,\n",
    "        'output_size':4,\n",
    "        'hidden_size':128,\n",
    "        'num_layer':2,\n",
    "        'epochs':40,\n",
    "        'learning_rate':0.001,\n",
    "        'seq_length': 120,\n",
    "        'batch_size': 100\n",
    "    }\n",
    "\n",
    "model_loss = {\n",
    "    's30_1':None,\n",
    "    's40_1':None,\n",
    "    's50_1':None,\n",
    "    's70_1':None,\n",
    "    's100_1':None,\n",
    "    'c30_1':None,\n",
    "    'c40_1':None,\n",
    "    'c50_1':None,\n",
    "    'c70_1':None,\n",
    "    'c100_1':None,\n",
    "\n",
    "    's30_2':None,\n",
    "    's40_2':None,\n",
    "    's50_2':None,\n",
    "    's70_2':None,\n",
    "    's100_2':None,\n",
    "    'c30_2':None,\n",
    "    'c40_2':None,\n",
    "    'c50_2':None,\n",
    "    'c70_2':None,\n",
    "    'c100_2':None,\n",
    "\n",
    "    's30_3':None,\n",
    "    's40_3':None,\n",
    "    's50_3':None,\n",
    "    's70_3':None,\n",
    "    's100_3':None,\n",
    "    'c30_3':None,\n",
    "    'c40_3':None,\n",
    "    'c50_3':None,\n",
    "    'c70_3':None,\n",
    "    'c100_3':None,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# LSTM 모델 정의\n",
    "class LSTMModel(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, num_layers, output_size):\n",
    "        super(LSTMModel, self).__init__()\n",
    "        self.lstm = nn.LSTM(input_size, hidden_size, num_layers, batch_first=True)\n",
    "        self.fc = nn.Linear(hidden_size, output_size)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        out, _ = self.lstm(x)\n",
    "        out = self.fc(out[:,:,:])  # 출력 레이어의 크기를 output_size로 변경\n",
    "        return out\n",
    "    \n",
    "#GRU 모델 정의\n",
    "class GRUModel(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, num_layers, output_size):\n",
    "        super(GRUModel, self).__init__()\n",
    "        self.gru = nn.GRU(input_size, hidden_size, num_layers, batch_first=True)\n",
    "        self.fc = nn.Linear(hidden_size, output_size)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        out, _ = self.gru(x)\n",
    "        out = self.fc(out)  # 마지막 시간 단계의 출력만 사용\n",
    "        return out\n",
    "\n",
    "#LSTM GRU 앙상블 모델 정의\n",
    "class LSTMGRUModel(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size_lstm, num_layers_lstm, hidden_size_gru, num_layers_gru, output_size):\n",
    "        super(LSTMGRUModel, self).__init__()\n",
    "        self.lstm = nn.LSTM(input_size, hidden_size_lstm, num_layers_lstm, batch_first=True)\n",
    "        self.gru = nn.GRU(hidden_size_lstm, hidden_size_gru, num_layers_gru, batch_first=True)\n",
    "        self.fc = nn.Linear(hidden_size_gru, output_size)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        lstm_out, _ = self.lstm(x)\n",
    "        gru_out, _ = self.gru(lstm_out)\n",
    "        out = self.fc(gru_out)  # 마지막 시간 단계의 출력만 사용\n",
    "        return out\n",
    "\n",
    "class BILSTMModel(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, num_layers, output_size, bidirectional=True, dropout_prob=0.2):\n",
    "        super(BILSTMModel, self).__init__()\n",
    "        self.lstm = nn.LSTM(input_size, hidden_size, num_layers, batch_first=True, bidirectional=bidirectional, dropout=dropout_prob)\n",
    "        num_directions = 2 if bidirectional else 1\n",
    "        self.fc = nn.Linear(hidden_size * num_directions, output_size)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        out, _ = self.lstm(x)\n",
    "        out = self.fc(out)  # 출력 레이어의 크기를 output_size로 변경\n",
    "        return out\n",
    "    \n",
    "class BILSTMGRUModel(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size_lstm, num_layers_lstm, hidden_size_gru, num_layers_gru, output_size, bidirectional=True, dropout_prob=0.2):\n",
    "        super(BILSTMGRUModel, self).__init__()\n",
    "        self.lstm = nn.LSTM(input_size, hidden_size_lstm, num_layers_lstm, batch_first=True, bidirectional=bidirectional, dropout=dropout_prob)   \n",
    "        num_directions = 2 if bidirectional else 1\n",
    "        self.gru = nn.GRU(hidden_size_lstm, hidden_size_gru, num_layers_gru, batch_first=True)\n",
    "        self.fc = nn.Linear(hidden_size_gru * num_directions, output_size)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        out, _ = self.lstm(x)\n",
    "        out = self.fc(out)  # 출력 레이어의 크기를 output_size로 변경\n",
    "        return out\n",
    "    \n",
    "class BiLSTMWithCNN(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, num_layers, output_size, bidirectional=True, dropout_prob=0.2, cnn_kernel_size=3, cnn_out_channels=64):\n",
    "        super(BiLSTMWithCNN, self).__init__()\n",
    "        \n",
    "        # Bidirectional LSTM\n",
    "        self.lstm = nn.LSTM(input_size, hidden_size, num_layers, batch_first=True, bidirectional=bidirectional, dropout=dropout_prob)\n",
    "        lstm_output_size = hidden_size * (2 if bidirectional else 1)\n",
    "        \n",
    "        # 1D-CNN layer\n",
    "        self.cnn = nn.Conv1d(in_channels=lstm_output_size, out_channels=cnn_out_channels, kernel_size=cnn_kernel_size)\n",
    "        \n",
    "        # Fully connected layer\n",
    "        self.fc = nn.Linear(cnn_out_channels, output_size)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        lstm_out, _ = self.lstm(x)\n",
    "        lstm_out = lstm_out.permute(0, 1, 2)  # LSTM 출력의 차원을 (배치, 시퀀스 길이, hidden_size)에서 (배치, hidden_size, 시퀀스 길이)로 변경\n",
    "        cnn_out = self.cnn(lstm_out)\n",
    "        cnn_out = torch.max(cnn_out, dim=1)[0]  # 시퀀스 길이 방향으로 최대 풀링\n",
    "        fc_out = self.fc(cnn_out)\n",
    "        return fc_out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_tensor(datas, sequence_length =100, stride=10):\n",
    "    train_data = []\n",
    "\n",
    "    for interval, data in datas.items():\n",
    "        \n",
    "        features = pd.merge(data[0].iloc[:10001, :31], data[1].iloc[:10001], on='Distance', how='inner').values\n",
    "        targets = data[0].iloc[:10001, 31:].values\n",
    "        test_features = pd.merge(data[0].iloc[10001:, :31], data[1].iloc[10001:], on='Distance', how='inner').values\n",
    "\n",
    "        features_tensor = torch.tensor(features, dtype=torch.float32).unfold(0, sequence_length, stride).permute(0,2,1)\n",
    "        targets_tensor = torch.tensor(targets, dtype=torch.float32).unfold(0, sequence_length, stride).permute(0,2,1)\n",
    "        test_data[interval] = torch.tensor(test_features, dtype=torch.float32).unsqueeze(1).expand(-1, sequence_length, -1)\n",
    "\n",
    "        print(features_tensor.shape, targets_tensor.shape)\n",
    "        train_dataset = TensorDataset(features_tensor, targets_tensor)\n",
    "        train_loader = DataLoader(dataset=train_dataset, batch_size=hyperparameter['batch_size'])\n",
    "        train_data.append(train_loader)\n",
    "\n",
    "    return train_data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([991, 100, 36]) torch.Size([991, 100, 4])\n",
      "torch.Size([991, 100, 36]) torch.Size([991, 100, 4])\n",
      "torch.Size([991, 100, 36]) torch.Size([991, 100, 4])\n",
      "torch.Size([991, 100, 36]) torch.Size([991, 100, 4])\n",
      "torch.Size([991, 100, 36]) torch.Size([991, 100, 4])\n",
      "torch.Size([991, 100, 34]) torch.Size([991, 100, 4])\n",
      "torch.Size([991, 100, 34]) torch.Size([991, 100, 4])\n",
      "torch.Size([991, 100, 34]) torch.Size([991, 100, 4])\n",
      "torch.Size([991, 100, 34]) torch.Size([991, 100, 4])\n",
      "torch.Size([991, 100, 34]) torch.Size([991, 100, 4])\n"
     ]
    }
   ],
   "source": [
    "s_train_data = create_tensor(s_datas)\n",
    "c_train_data = create_tensor(c_datas)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "s_model1 = LSTMModel(hyperparameter['s_input_size'], hyperparameter['hidden_size'], hyperparameter['num_layer'], hyperparameter['output_size'])\n",
    "s_model2 = GRUModel(hyperparameter['s_input_size'], hyperparameter['hidden_size'], hyperparameter['num_layer'], hyperparameter['output_size'])\n",
    "s_model3 = LSTMGRUModel(hyperparameter['s_input_size'], hyperparameter['hidden_size'], hyperparameter['num_layer'], hyperparameter['hidden_size'], hyperparameter['num_layer'], hyperparameter['output_size'])\n",
    "s_model4 = BILSTMModel(hyperparameter['s_input_size'], hyperparameter['hidden_size'], hyperparameter['num_layer'], hyperparameter['output_size'])\n",
    "s_model5 = BILSTMGRUModel(hyperparameter['s_input_size'], hyperparameter['hidden_size'], hyperparameter['num_layer'], hyperparameter['hidden_size'], hyperparameter['num_layer'], hyperparameter['output_size'])\n",
    "s_model6 = BiLSTMWithCNN(hyperparameter['s_input_size'], hyperparameter['hidden_size'], hyperparameter['num_layer'], hyperparameter['output_size'])\n",
    "\n",
    "c_model1 = LSTMModel(hyperparameter['c_input_size'], hyperparameter['hidden_size'], hyperparameter['num_layer'], hyperparameter['output_size'])\n",
    "c_model2 = GRUModel(hyperparameter['c_input_size'], hyperparameter['hidden_size'], hyperparameter['num_layer'], hyperparameter['output_size'])\n",
    "c_model3 = LSTMGRUModel(hyperparameter['c_input_size'], hyperparameter['hidden_size'], hyperparameter['num_layer'], hyperparameter['hidden_size'], hyperparameter['num_layer'], hyperparameter['output_size'])\n",
    "c_model4 = BILSTMModel(hyperparameter['c_input_size'], hyperparameter['hidden_size'], hyperparameter['num_layer'], hyperparameter['output_size'])\n",
    "c_model5 = BILSTMGRUModel(hyperparameter['c_input_size'], hyperparameter['hidden_size'], hyperparameter['num_layer'], hyperparameter['hidden_size'], hyperparameter['num_layer'], hyperparameter['output_size'])\n",
    "c_model6 = BiLSTMWithCNN(hyperparameter['c_input_size'], hyperparameter['hidden_size'], hyperparameter['num_layer'], hyperparameter['output_size'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "start model learning\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "231233a7c8004e6fbe75a0b7ebbc0deb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "epoch:   0%|          | 0/40 [00:00<?, ?epoch/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/40], Loss: 0.000944, Time: 166.587 seconds\n",
      "Epoch [2/40], Loss: 0.000776, Time: 177.192 seconds\n",
      "Epoch [3/40], Loss: 0.000634, Time: 144.031 seconds\n",
      "Epoch [4/40], Loss: 0.000370, Time: 137.477 seconds\n",
      "Epoch [5/40], Loss: 0.000243, Time: 134.167 seconds\n",
      "Epoch [6/40], Loss: 0.000294, Time: 134.104 seconds\n",
      "Epoch [7/40], Loss: 0.000600, Time: 132.911 seconds\n",
      "Epoch [8/40], Loss: 0.000173, Time: 145.200 seconds\n",
      "Epoch [9/40], Loss: 0.000183, Time: 147.860 seconds\n",
      "Epoch [10/40], Loss: 0.000201, Time: 147.754 seconds\n",
      "Epoch [11/40], Loss: 0.000118, Time: 147.805 seconds\n",
      "Epoch [12/40], Loss: 0.000135, Time: 148.062 seconds\n",
      "Epoch [13/40], Loss: 0.000310, Time: 147.813 seconds\n",
      "Epoch [14/40], Loss: 0.000163, Time: 152.883 seconds\n",
      "Epoch [15/40], Loss: 0.000135, Time: 148.080 seconds\n",
      "Epoch [16/40], Loss: 0.000318, Time: 147.455 seconds\n",
      "Epoch [17/40], Loss: 0.000224, Time: 148.304 seconds\n",
      "Epoch [18/40], Loss: 0.000154, Time: 150.620 seconds\n",
      "Epoch [19/40], Loss: 0.000235, Time: 150.599 seconds\n",
      "Epoch [20/40], Loss: 0.000125, Time: 150.137 seconds\n",
      "Epoch [21/40], Loss: 0.000187, Time: 148.300 seconds\n",
      "Epoch [22/40], Loss: 0.000119, Time: 148.829 seconds\n",
      "Epoch [23/40], Loss: 0.000124, Time: 147.958 seconds\n",
      "Epoch [24/40], Loss: 0.000095, Time: 148.546 seconds\n",
      "Epoch [25/40], Loss: 0.000079, Time: 150.849 seconds\n",
      "Epoch [26/40], Loss: 0.000119, Time: 149.367 seconds\n",
      "Epoch [27/40], Loss: 0.000182, Time: 148.825 seconds\n",
      "Epoch [28/40], Loss: 0.000114, Time: 156.022 seconds\n",
      "Epoch [29/40], Loss: 0.000106, Time: 149.273 seconds\n",
      "Epoch [30/40], Loss: 0.000121, Time: 153.537 seconds\n",
      "Epoch [31/40], Loss: 0.000126, Time: 150.792 seconds\n",
      "Epoch [32/40], Loss: 0.000100, Time: 149.927 seconds\n",
      "Epoch [33/40], Loss: 0.000110, Time: 149.674 seconds\n",
      "Epoch [34/40], Loss: 0.000144, Time: 150.258 seconds\n",
      "Epoch [35/40], Loss: 0.000094, Time: 155.891 seconds\n",
      "Epoch [36/40], Loss: 0.000078, Time: 159.200 seconds\n",
      "Epoch [37/40], Loss: 0.000125, Time: 153.819 seconds\n",
      "Epoch [38/40], Loss: 0.000077, Time: 152.874 seconds\n",
      "Epoch [39/40], Loss: 0.000073, Time: 154.592 seconds\n",
      "Epoch [40/40], Loss: 0.000115, Time: 148.567 seconds\n",
      "start model learning\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "44a8553df6a644e3871faf40c895c79d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "epoch:   0%|          | 0/40 [00:00<?, ?epoch/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/40], Loss: 0.001497, Time: 143.680 seconds\n",
      "Epoch [2/40], Loss: 0.000923, Time: 149.865 seconds\n",
      "Epoch [3/40], Loss: 0.000954, Time: 148.341 seconds\n",
      "Epoch [4/40], Loss: 0.000842, Time: 150.907 seconds\n",
      "Epoch [5/40], Loss: 0.000818, Time: 150.351 seconds\n",
      "Epoch [6/40], Loss: 0.000968, Time: 152.689 seconds\n",
      "Epoch [7/40], Loss: 0.000693, Time: 150.249 seconds\n",
      "Epoch [8/40], Loss: 0.000587, Time: 150.193 seconds\n",
      "Epoch [9/40], Loss: 0.000849, Time: 149.251 seconds\n",
      "Epoch [10/40], Loss: 0.000400, Time: 149.827 seconds\n",
      "Epoch [11/40], Loss: 0.000812, Time: 147.893 seconds\n",
      "Epoch [12/40], Loss: 0.000407, Time: 148.889 seconds\n",
      "Epoch [13/40], Loss: 0.000528, Time: 147.903 seconds\n",
      "Epoch [14/40], Loss: 0.000320, Time: 148.948 seconds\n",
      "Epoch [15/40], Loss: 0.000555, Time: 148.277 seconds\n",
      "Epoch [16/40], Loss: 0.000357, Time: 149.447 seconds\n",
      "Epoch [17/40], Loss: 0.000827, Time: 148.773 seconds\n",
      "Epoch [18/40], Loss: 0.000267, Time: 152.636 seconds\n",
      "Epoch [19/40], Loss: 0.000375, Time: 148.384 seconds\n",
      "Epoch [20/40], Loss: 0.000362, Time: 149.974 seconds\n",
      "Epoch [21/40], Loss: 0.000384, Time: 149.389 seconds\n",
      "Epoch [22/40], Loss: 0.000625, Time: 147.487 seconds\n",
      "Epoch [23/40], Loss: 0.000224, Time: 148.360 seconds\n",
      "Epoch [24/40], Loss: 0.000257, Time: 147.919 seconds\n",
      "Epoch [25/40], Loss: 0.000654, Time: 149.682 seconds\n",
      "Epoch [26/40], Loss: 0.000216, Time: 150.563 seconds\n",
      "Epoch [27/40], Loss: 0.000237, Time: 148.437 seconds\n",
      "Epoch [28/40], Loss: 0.000198, Time: 152.075 seconds\n",
      "Epoch [29/40], Loss: 0.000438, Time: 153.979 seconds\n",
      "Epoch [30/40], Loss: 0.000196, Time: 158.228 seconds\n",
      "Epoch [31/40], Loss: 0.000405, Time: 154.602 seconds\n",
      "Epoch [32/40], Loss: 0.000184, Time: 156.368 seconds\n",
      "Epoch [33/40], Loss: 0.000199, Time: 155.671 seconds\n",
      "Epoch [34/40], Loss: 0.000186, Time: 155.081 seconds\n",
      "Epoch [35/40], Loss: 0.000355, Time: 154.495 seconds\n",
      "Epoch [36/40], Loss: 0.000324, Time: 154.135 seconds\n",
      "Epoch [37/40], Loss: 0.000280, Time: 154.280 seconds\n",
      "Epoch [38/40], Loss: 0.000209, Time: 156.231 seconds\n",
      "Epoch [39/40], Loss: 0.000159, Time: 150.803 seconds\n",
      "Epoch [40/40], Loss: 0.000165, Time: 155.181 seconds\n",
      "start model learning\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3174c2a3c7fb491282ee7a5bb88826d5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "epoch:   0%|          | 0/40 [00:00<?, ?epoch/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "RuntimeError",
     "evalue": "Given groups=1, weight of size [64, 256, 3], expected input[100, 100, 256] to have 256 channels, but got 100 channels instead",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[17], line 30\u001b[0m\n\u001b[0;32m     28\u001b[0m \u001b[39mfor\u001b[39;00m t_data \u001b[39min\u001b[39;00m train_data:\n\u001b[0;32m     29\u001b[0m     \u001b[39mfor\u001b[39;00m \u001b[39minput\u001b[39m, labels \u001b[39min\u001b[39;00m t_data:\n\u001b[1;32m---> 30\u001b[0m         outputs \u001b[39m=\u001b[39m model(\u001b[39minput\u001b[39;49m)\n\u001b[0;32m     31\u001b[0m         loss \u001b[39m=\u001b[39m criterion(outputs, labels)\n\u001b[0;32m     32\u001b[0m         optimizer\u001b[39m.\u001b[39mzero_grad()\n",
      "File \u001b[1;32mc:\\ProgramData\\Anaconda3\\envs\\Aivenv\\lib\\site-packages\\torch\\nn\\modules\\module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1496\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1497\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1498\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_pre_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1499\u001b[0m         \u001b[39mor\u001b[39;00m _global_backward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1500\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1501\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m   1502\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[0;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "Cell \u001b[1;32mIn[12], line 81\u001b[0m, in \u001b[0;36mBiLSTMWithCNN.forward\u001b[1;34m(self, x)\u001b[0m\n\u001b[0;32m     79\u001b[0m lstm_out, _ \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mlstm(x)\n\u001b[0;32m     80\u001b[0m lstm_out \u001b[39m=\u001b[39m lstm_out\u001b[39m.\u001b[39mpermute(\u001b[39m0\u001b[39m, \u001b[39m1\u001b[39m, \u001b[39m2\u001b[39m)  \u001b[39m# LSTM 출력의 차원을 (배치, 시퀀스 길이, hidden_size)에서 (배치, hidden_size, 시퀀스 길이)로 변경\u001b[39;00m\n\u001b[1;32m---> 81\u001b[0m cnn_out \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mcnn(lstm_out)\n\u001b[0;32m     82\u001b[0m cnn_out \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39mmax(cnn_out, dim\u001b[39m=\u001b[39m\u001b[39m1\u001b[39m)[\u001b[39m0\u001b[39m]  \u001b[39m# 시퀀스 길이 방향으로 최대 풀링\u001b[39;00m\n\u001b[0;32m     83\u001b[0m fc_out \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mfc(cnn_out)\n",
      "File \u001b[1;32mc:\\ProgramData\\Anaconda3\\envs\\Aivenv\\lib\\site-packages\\torch\\nn\\modules\\module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1496\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1497\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1498\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_pre_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1499\u001b[0m         \u001b[39mor\u001b[39;00m _global_backward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1500\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1501\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m   1502\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[0;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[1;32mc:\\ProgramData\\Anaconda3\\envs\\Aivenv\\lib\\site-packages\\torch\\nn\\modules\\conv.py:313\u001b[0m, in \u001b[0;36mConv1d.forward\u001b[1;34m(self, input)\u001b[0m\n\u001b[0;32m    312\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mforward\u001b[39m(\u001b[39mself\u001b[39m, \u001b[39minput\u001b[39m: Tensor) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m Tensor:\n\u001b[1;32m--> 313\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_conv_forward(\u001b[39minput\u001b[39;49m, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mweight, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mbias)\n",
      "File \u001b[1;32mc:\\ProgramData\\Anaconda3\\envs\\Aivenv\\lib\\site-packages\\torch\\nn\\modules\\conv.py:309\u001b[0m, in \u001b[0;36mConv1d._conv_forward\u001b[1;34m(self, input, weight, bias)\u001b[0m\n\u001b[0;32m    305\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mpadding_mode \u001b[39m!=\u001b[39m \u001b[39m'\u001b[39m\u001b[39mzeros\u001b[39m\u001b[39m'\u001b[39m:\n\u001b[0;32m    306\u001b[0m     \u001b[39mreturn\u001b[39;00m F\u001b[39m.\u001b[39mconv1d(F\u001b[39m.\u001b[39mpad(\u001b[39minput\u001b[39m, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_reversed_padding_repeated_twice, mode\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mpadding_mode),\n\u001b[0;32m    307\u001b[0m                     weight, bias, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mstride,\n\u001b[0;32m    308\u001b[0m                     _single(\u001b[39m0\u001b[39m), \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdilation, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mgroups)\n\u001b[1;32m--> 309\u001b[0m \u001b[39mreturn\u001b[39;00m F\u001b[39m.\u001b[39;49mconv1d(\u001b[39minput\u001b[39;49m, weight, bias, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mstride,\n\u001b[0;32m    310\u001b[0m                 \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mpadding, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mdilation, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mgroups)\n",
      "\u001b[1;31mRuntimeError\u001b[0m: Given groups=1, weight of size [64, 256, 3], expected input[100, 100, 256] to have 256 channels, but got 100 channels instead"
     ]
    }
   ],
   "source": [
    "#모델 학습 -> s, c 별로 1,3 번 모델 학습\n",
    "\n",
    "cnt = 4\n",
    "model_list = [(s_model1, c_model1),(s_model2, c_model2),(s_model3, c_model3),(s_model4, c_model4),(s_model5, c_model5),(s_model6, c_model6)]\n",
    "\n",
    "for models in model_list[cnt:]:\n",
    "    for train_data in [s_train_data,c_train_data]:\n",
    "\n",
    "        if train_data == s_train_data:\n",
    "            st = 's'\n",
    "            model = models[0]\n",
    "        else:\n",
    "            st = 'c'\n",
    "            model = models[1]\n",
    "\n",
    "\n",
    "        criterion = nn.MSELoss()\n",
    "        optimizer = torch.optim.Adam(model.parameters(), lr=hyperparameter['learning_rate'])\n",
    "\n",
    "        # 모델 학습\n",
    "        print(f'start model learning')\n",
    "        data_loss = 0\n",
    "\n",
    "        epochs = hyperparameter['epochs']\n",
    "            \n",
    "        for epoch in tqdm(range(epochs), desc=\"epoch\", unit='epoch'):\n",
    "            start_time = time.time()\n",
    "            for t_data in train_data:\n",
    "                for input, labels in t_data:\n",
    "                    outputs = model(input)\n",
    "                    loss = criterion(outputs, labels)\n",
    "                    optimizer.zero_grad()\n",
    "                    loss.backward()\n",
    "                    optimizer.step()\n",
    "                            \n",
    "            end_time = time.time()\n",
    "            epoch_time = end_time - start_time\n",
    "\n",
    "            tqdm.write(f'Epoch [{epoch+1}/{epochs}], Loss: {loss.item():.6f}, Time: {epoch_time:.3f} seconds')\n",
    "            data_loss = loss.item()\n",
    "\n",
    "\n",
    "            torch.save(model.state_dict(), f'./model/{st}/model{cnt}_weights_ver1.pth')\n",
    "            \n",
    "cnt += 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "#모델 weight loading\n",
    "\n",
    "def LSTMmodel_loading():\n",
    "    c_weights_path = './model/c/LSTM_weights_ver1.pth'\n",
    "    c_model1.load_state_dict(torch.load(c_weights_path))\n",
    "    c_model1.eval()\n",
    "\n",
    "    s_weights_path = './model/s/LSTM_weights_ver1.pth'\n",
    "    s_model1.load_state_dict(torch.load(s_weights_path))\n",
    "    s_model1.eval()\n",
    "\n",
    "def LSTMGRUmodel_loading():\n",
    "    c_weights_path = './model/c/model_weights_4.pth'\n",
    "    c_model3.load_state_dict(torch.load(c_weights_path))\n",
    "    c_model3.eval()\n",
    "\n",
    "    s_weights_path = './model/s/model_weights_2.pth'\n",
    "    s_model3.load_state_dict(torch.load(s_weights_path))\n",
    "    s_model3.eval()\n",
    "\n",
    "def BILSTMmodel_loading():\n",
    "    c_weights_path = './model/c/BILSTM_weights.pth'\n",
    "    c_model4.load_state_dict(torch.load(c_weights_path))\n",
    "    c_model4.eval()\n",
    "\n",
    "    s_weights_path = './model/s/BILSTM_weights.pth'\n",
    "    s_model4.load_state_dict(torch.load(s_weights_path))\n",
    "    s_model4.eval()\n",
    "\n",
    "def BILSTMGRUmodel_loading():\n",
    "    c_weights_path = './model/c/model4_weights_ver1.pth'\n",
    "    c_model5.load_state_dict(torch.load(c_weights_path))\n",
    "    c_model5.eval()\n",
    "\n",
    "    s_weights_path = './model/s/model4_weights_ver1.pth'\n",
    "    s_model5.load_state_dict(torch.load(s_weights_path))\n",
    "    s_model5.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_prediction(s_model, c_model, test_data):\n",
    "    result_tensor = torch.empty(0)\n",
    "\n",
    "    for column, tensor in test_data.items():\n",
    "        if column[0] == 's':    \n",
    "            with torch.no_grad():\n",
    "                predictions = s_model(tensor)\n",
    "                print(predictions.shape)\n",
    "        else:\n",
    "            with torch.no_grad():\n",
    "                predictions = c_model(tensor)\n",
    "                print(predictions.shape)\n",
    "\n",
    "        result_tensor = torch.cat((result_tensor, predictions), dim=2)\n",
    "\n",
    "    return result_tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1999, 100, 4])\n",
      "torch.Size([1999, 100, 4])\n",
      "torch.Size([1999, 100, 4])\n",
      "torch.Size([1999, 100, 4])\n",
      "torch.Size([1999, 100, 4])\n",
      "torch.Size([1999, 100, 4])\n",
      "torch.Size([1999, 100, 4])\n",
      "torch.Size([1999, 100, 4])\n",
      "torch.Size([1999, 100, 4])\n",
      "torch.Size([1999, 100, 4])\n"
     ]
    }
   ],
   "source": [
    "#LSTMmodel_loading()\n",
    "# LSTMGRUmodel_loading()\n",
    "# BILSTMmodel_loading()\n",
    "BILSTMGRUmodel_loading()\n",
    "\n",
    "result_tensor = data_prediction(s_model1, c_model1, test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1999, 100, 40])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result_tensor.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1999, 40)\n"
     ]
    }
   ],
   "source": [
    "result_array = result_tensor[:,-1,:].numpy()\n",
    "print(result_array.shape)\n",
    "result_df = pd.DataFrame(result_array, columns=[\n",
    "    'YL_M1_B1_W1_s30','YR_M1_B1_W1_s30','YL_M1_B1_W2_s30','YR_M1_B1_W2_s30',\n",
    "    'YL_M1_B1_W1_s40','YR_M1_B1_W1_s40','YL_M1_B1_W2_s40','YR_M1_B1_W2_s40',\n",
    "    'YL_M1_B1_W1_s50','YR_M1_B1_W1_s50','YL_M1_B1_W2_s50','YR_M1_B1_W2_s50',\n",
    "    'YL_M1_B1_W1_s70','YR_M1_B1_W1_s70','YL_M1_B1_W2_s70','YR_M1_B1_W2_s70',\n",
    "    'YL_M1_B1_W1_s100','YR_M1_B1_W1_s100','YL_M1_B1_W2_s100','YR_M1_B1_W2_s100',\n",
    "    'YL_M1_B1_W1_c30','YR_M1_B1_W1_c30','YL_M1_B1_W2_c30','YR_M1_B1_W2_c30',\n",
    "    'YL_M1_B1_W1_c40','YR_M1_B1_W1_c40','YL_M1_B1_W2_c40','YR_M1_B1_W2_c40',\n",
    "    'YL_M1_B1_W1_c50','YR_M1_B1_W1_c50','YL_M1_B1_W2_c50','YR_M1_B1_W2_c50',\n",
    "    'YL_M1_B1_W1_c70','YR_M1_B1_W1_c70','YL_M1_B1_W2_c70','YR_M1_B1_W2_c70',\n",
    "    'YL_M1_B1_W1_c100','YR_M1_B1_W1_c100','YL_M1_B1_W2_c100','YR_M1_B1_W2_c100'\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>YL_M1_B1_W1_s30</th>\n",
       "      <th>YR_M1_B1_W1_s30</th>\n",
       "      <th>YL_M1_B1_W2_s30</th>\n",
       "      <th>YR_M1_B1_W2_s30</th>\n",
       "      <th>YL_M1_B1_W1_s40</th>\n",
       "      <th>YR_M1_B1_W1_s40</th>\n",
       "      <th>YL_M1_B1_W2_s40</th>\n",
       "      <th>YR_M1_B1_W2_s40</th>\n",
       "      <th>YL_M1_B1_W1_s50</th>\n",
       "      <th>YR_M1_B1_W1_s50</th>\n",
       "      <th>...</th>\n",
       "      <th>YL_M1_B1_W2_c50</th>\n",
       "      <th>YR_M1_B1_W2_c50</th>\n",
       "      <th>YL_M1_B1_W1_c70</th>\n",
       "      <th>YR_M1_B1_W1_c70</th>\n",
       "      <th>YL_M1_B1_W2_c70</th>\n",
       "      <th>YR_M1_B1_W2_c70</th>\n",
       "      <th>YL_M1_B1_W1_c100</th>\n",
       "      <th>YR_M1_B1_W1_c100</th>\n",
       "      <th>YL_M1_B1_W2_c100</th>\n",
       "      <th>YR_M1_B1_W2_c100</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.150981</td>\n",
       "      <td>-0.098702</td>\n",
       "      <td>0.00529</td>\n",
       "      <td>0.086255</td>\n",
       "      <td>0.15069</td>\n",
       "      <td>-0.101257</td>\n",
       "      <td>0.005077</td>\n",
       "      <td>0.086646</td>\n",
       "      <td>0.150823</td>\n",
       "      <td>-0.100702</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.020597</td>\n",
       "      <td>-0.048949</td>\n",
       "      <td>0.007647</td>\n",
       "      <td>0.008993</td>\n",
       "      <td>-0.020594</td>\n",
       "      <td>-0.048955</td>\n",
       "      <td>0.007646</td>\n",
       "      <td>0.008993</td>\n",
       "      <td>-0.020594</td>\n",
       "      <td>-0.048955</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1 rows × 40 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   YL_M1_B1_W1_s30  YR_M1_B1_W1_s30  YL_M1_B1_W2_s30  YR_M1_B1_W2_s30  \\\n",
       "0         0.150981        -0.098702          0.00529         0.086255   \n",
       "\n",
       "   YL_M1_B1_W1_s40  YR_M1_B1_W1_s40  YL_M1_B1_W2_s40  YR_M1_B1_W2_s40  \\\n",
       "0          0.15069        -0.101257         0.005077         0.086646   \n",
       "\n",
       "   YL_M1_B1_W1_s50  YR_M1_B1_W1_s50  ...  YL_M1_B1_W2_c50  YR_M1_B1_W2_c50  \\\n",
       "0         0.150823        -0.100702  ...        -0.020597        -0.048949   \n",
       "\n",
       "   YL_M1_B1_W1_c70  YR_M1_B1_W1_c70  YL_M1_B1_W2_c70  YR_M1_B1_W2_c70  \\\n",
       "0         0.007647         0.008993        -0.020594        -0.048955   \n",
       "\n",
       "   YL_M1_B1_W1_c100  YR_M1_B1_W1_c100  YL_M1_B1_W2_c100  YR_M1_B1_W2_c100  \n",
       "0          0.007646          0.008993         -0.020594         -0.048955  \n",
       "\n",
       "[1 rows x 40 columns]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result_df.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0       2500.25\n",
       "1       2500.50\n",
       "2       2500.75\n",
       "3       2501.00\n",
       "4       2501.25\n",
       "         ...   \n",
       "1994    2998.75\n",
       "1995    2999.00\n",
       "1996    2999.25\n",
       "1997    2999.50\n",
       "1998    2999.75\n",
       "Name: Distance, Length: 1999, dtype: float64"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "distance = lane_data_c['Distance'][10001:]\n",
    "distance = distance.reset_index(drop=True)\n",
    "distance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Distance</th>\n",
       "      <th>YL_M1_B1_W1_s30</th>\n",
       "      <th>YR_M1_B1_W1_s30</th>\n",
       "      <th>YL_M1_B1_W2_s30</th>\n",
       "      <th>YR_M1_B1_W2_s30</th>\n",
       "      <th>YL_M1_B1_W1_s40</th>\n",
       "      <th>YR_M1_B1_W1_s40</th>\n",
       "      <th>YL_M1_B1_W2_s40</th>\n",
       "      <th>YR_M1_B1_W2_s40</th>\n",
       "      <th>YL_M1_B1_W1_s50</th>\n",
       "      <th>...</th>\n",
       "      <th>YL_M1_B1_W2_c50</th>\n",
       "      <th>YR_M1_B1_W2_c50</th>\n",
       "      <th>YL_M1_B1_W1_c70</th>\n",
       "      <th>YR_M1_B1_W1_c70</th>\n",
       "      <th>YL_M1_B1_W2_c70</th>\n",
       "      <th>YR_M1_B1_W2_c70</th>\n",
       "      <th>YL_M1_B1_W1_c100</th>\n",
       "      <th>YR_M1_B1_W1_c100</th>\n",
       "      <th>YL_M1_B1_W2_c100</th>\n",
       "      <th>YR_M1_B1_W2_c100</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2500.25</td>\n",
       "      <td>0.150981</td>\n",
       "      <td>-0.098702</td>\n",
       "      <td>0.00529</td>\n",
       "      <td>0.086255</td>\n",
       "      <td>0.15069</td>\n",
       "      <td>-0.101257</td>\n",
       "      <td>0.005077</td>\n",
       "      <td>0.086646</td>\n",
       "      <td>0.150823</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.020597</td>\n",
       "      <td>-0.048949</td>\n",
       "      <td>0.007647</td>\n",
       "      <td>0.008993</td>\n",
       "      <td>-0.020594</td>\n",
       "      <td>-0.048955</td>\n",
       "      <td>0.007646</td>\n",
       "      <td>0.008993</td>\n",
       "      <td>-0.020594</td>\n",
       "      <td>-0.048955</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1 rows × 41 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Distance  YL_M1_B1_W1_s30  YR_M1_B1_W1_s30  YL_M1_B1_W2_s30  \\\n",
       "0   2500.25         0.150981        -0.098702          0.00529   \n",
       "\n",
       "   YR_M1_B1_W2_s30  YL_M1_B1_W1_s40  YR_M1_B1_W1_s40  YL_M1_B1_W2_s40  \\\n",
       "0         0.086255          0.15069        -0.101257         0.005077   \n",
       "\n",
       "   YR_M1_B1_W2_s40  YL_M1_B1_W1_s50  ...  YL_M1_B1_W2_c50  YR_M1_B1_W2_c50  \\\n",
       "0         0.086646         0.150823  ...        -0.020597        -0.048949   \n",
       "\n",
       "   YL_M1_B1_W1_c70  YR_M1_B1_W1_c70  YL_M1_B1_W2_c70  YR_M1_B1_W2_c70  \\\n",
       "0         0.007647         0.008993        -0.020594        -0.048955   \n",
       "\n",
       "   YL_M1_B1_W1_c100  YR_M1_B1_W1_c100  YL_M1_B1_W2_c100  YR_M1_B1_W2_c100  \n",
       "0          0.007646          0.008993         -0.020594         -0.048955  \n",
       "\n",
       "[1 rows x 41 columns]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result_df = pd.concat([distance,result_df], axis=1)\n",
    "result_df.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "result_df.to_csv('./result/answer_BILSTMGRU_ver1.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Aivenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
